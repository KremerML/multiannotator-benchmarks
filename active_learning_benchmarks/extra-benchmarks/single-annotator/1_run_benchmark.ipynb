{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cleanlab.multiannotator import get_majority_vote_label, get_label_quality_multiannotator, get_active_learning_scores\n",
    "from cleanlab.internal.label_quality_utils import get_normalized_entropy\n",
    "\n",
    "from utils.model_training import fit_predict_proba\n",
    "from utils.active_learning import setup_next_iter_data, get_idx_to_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files\n",
    "\n",
    "The datafiles can either be generate yourself by running [0_create_data.ipynb](0_create_data.ipynb), or by downloading our pre-generated files using the commands:\n",
    "\n",
    "```\n",
    "wget -nc 'https://cleanlab-public.s3.amazonaws.com/ActiveLearning/Benchmark/SingleAnnotator/data.tar.gz'\n",
    "tar -xf data.tar.gz data/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 10\n",
    "num_iter = 5\n",
    "batch_size_to_label = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    X_labeled =  np.load(\"data/X_labeled.npy\")\n",
    "    X_unlabeled =  np.load(\"data/X_unlabeled.npy\")\n",
    "    X_test =  np.load(\"data/X_test.npy\")\n",
    "\n",
    "    true_labels_labeled =  np.load(\"data/true_labels_labeled.npy\")\n",
    "    true_labels_unlabeled =  np.load(\"data/true_labels_unlabeled.npy\")\n",
    "    true_labels_test =  np.load(\"data/true_labels_test.npy\")\n",
    "\n",
    "    y_labeled =  np.load(\"data/noisy_labels_labeled.npy\")\n",
    "    y_unlabeled =  np.load(\"data/noisy_labels_unlabeled.npy\")\n",
    "\n",
    "    return X_labeled, X_unlabeled, X_test, y_labeled, y_unlabeled, true_labels_labeled, true_labels_unlabeled, true_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy \n",
    "for i in range(num_iter):\n",
    "    (\n",
    "        X_labeled, \n",
    "        X_unlabeled, \n",
    "        X_test, \n",
    "        y_labeled, \n",
    "        y_unlabeled, \n",
    "        true_labels_labeled, \n",
    "        true_labels_unlabeled, \n",
    "        true_labels_test\n",
    "    ) = get_data()\n",
    "\n",
    "    entropy_model_accuracy_arr = np.full(num_rounds, np.nan)\n",
    "\n",
    "    for k in range(num_rounds):\n",
    "        pred_probs, pred_probs_unlabeled = fit_predict_proba(\n",
    "            ExtraTreesClassifier(),\n",
    "            X_labeled,\n",
    "            y_labeled,\n",
    "            cv_n_folds=5,\n",
    "            X_unlabeled=X_unlabeled,\n",
    "        )\n",
    "\n",
    "        single_model = ExtraTreesClassifier()\n",
    "        single_model.fit(X_labeled, y_labeled)\n",
    "        single_pred_labels = single_model.predict(X_test)\n",
    "        entropy_model_accuracy_arr[k] = np.mean(single_pred_labels == true_labels_test)\n",
    "\n",
    "        quality_of_consensus = - get_normalized_entropy(pred_probs_unlabeled)\n",
    "\n",
    "        relabel_idx = np.array([])\n",
    "        relabel_idx_unlabeled = np.argsort(quality_of_consensus)[:batch_size_to_label]\n",
    "\n",
    "        y_labeled = np.concatenate((y_labeled, y_unlabeled[relabel_idx_unlabeled]))\n",
    "\n",
    "        (\n",
    "            relabel_idx_combined, X_labeled, X_unlabeled, true_labels_labeled, \n",
    "            true_labels_unlabeled, pred_probs_labeled, \n",
    "            pred_probs_unlabeled, y_unlabeled\n",
    "        ) = setup_next_iter_data(\n",
    "            relabel_idx, relabel_idx_unlabeled, X_labeled, X_unlabeled, \n",
    "            true_labels_labeled, true_labels_unlabeled, pred_probs, \n",
    "            pred_probs_unlabeled, y_unlabeled\n",
    "        )\n",
    "\n",
    "    np.save(f\"results/entropy_{i}.npy\", entropy_model_accuracy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random \n",
    "for i in range(num_iter):\n",
    "    (\n",
    "        X_labeled, \n",
    "        X_unlabeled, \n",
    "        X_test, \n",
    "        y_labeled, \n",
    "        y_unlabeled, \n",
    "        true_labels_labeled, \n",
    "        true_labels_unlabeled, \n",
    "        true_labels_test\n",
    "    ) = get_data()\n",
    "\n",
    "    random_model_accuracy_arr = np.full(num_rounds, np.nan)\n",
    "\n",
    "    for k in range(num_rounds):\n",
    "        pred_probs, pred_probs_unlabeled = fit_predict_proba(\n",
    "            ExtraTreesClassifier(),\n",
    "            X_labeled,\n",
    "            y_labeled,\n",
    "            cv_n_folds=5,\n",
    "            X_unlabeled=X_unlabeled,\n",
    "        )\n",
    "\n",
    "        single_model = ExtraTreesClassifier()\n",
    "        single_model.fit(X_labeled, y_labeled)\n",
    "        single_pred_labels = single_model.predict(X_test)\n",
    "        random_model_accuracy_arr[k] = np.mean(single_pred_labels == true_labels_test)\n",
    "\n",
    "        quality_of_consensus = np.random.rand(len(pred_probs_unlabeled))\n",
    "\n",
    "        relabel_idx = np.array([])\n",
    "        relabel_idx_unlabeled = np.argsort(quality_of_consensus)[:batch_size_to_label]\n",
    "\n",
    "        y_labeled = np.concatenate((y_labeled, y_unlabeled[relabel_idx_unlabeled]))\n",
    "\n",
    "        (\n",
    "            relabel_idx_combined, X_labeled, X_unlabeled, true_labels_labeled, \n",
    "            true_labels_unlabeled, pred_probs_labeled, \n",
    "            pred_probs_unlabeled, y_unlabeled\n",
    "        ) = setup_next_iter_data(\n",
    "            relabel_idx, relabel_idx_unlabeled, X_labeled, X_unlabeled, \n",
    "            true_labels_labeled, true_labels_unlabeled, pred_probs, \n",
    "            pred_probs_unlabeled, y_unlabeled\n",
    "        )\n",
    "\n",
    "    np.save(f\"results/random_{i}.npy\", random_model_accuracy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crowdlab \n",
    "for i in range(num_iter):\n",
    "    (\n",
    "        X_labeled, \n",
    "        X_unlabeled, \n",
    "        X_test, \n",
    "        y_labeled, \n",
    "        y_unlabeled, \n",
    "        true_labels_labeled, \n",
    "        true_labels_unlabeled, \n",
    "        true_labels_test\n",
    "    ) = get_data()\n",
    "\n",
    "    crowdlab_model_accuracy_arr = np.full(num_rounds, np.nan)\n",
    "\n",
    "    for k in range(num_rounds):\n",
    "        pred_probs, pred_probs_unlabeled = fit_predict_proba(\n",
    "            ExtraTreesClassifier(),\n",
    "            X_labeled,\n",
    "            y_labeled,\n",
    "            cv_n_folds=5,\n",
    "            X_unlabeled=X_unlabeled,\n",
    "        )\n",
    "\n",
    "        single_model = ExtraTreesClassifier()\n",
    "        single_model.fit(X_labeled, y_labeled)\n",
    "        single_pred_labels = single_model.predict(X_test)\n",
    "        crowdlab_model_accuracy_arr[k] = np.mean(single_pred_labels == true_labels_test)\n",
    "\n",
    "        _, quality_of_consensus = get_active_learning_scores(\n",
    "            y_labeled, pred_probs, pred_probs_unlabeled\n",
    "        )\n",
    "\n",
    "        relabel_idx = np.array([])\n",
    "        relabel_idx_unlabeled = np.argsort(quality_of_consensus)[:batch_size_to_label]\n",
    "\n",
    "        y_labeled = np.concatenate((y_labeled, y_unlabeled[relabel_idx_unlabeled]))\n",
    "\n",
    "        (\n",
    "            relabel_idx_combined, X_labeled, X_unlabeled, true_labels_labeled, \n",
    "            true_labels_unlabeled, pred_probs_labeled, \n",
    "            pred_probs_unlabeled, y_unlabeled\n",
    "        ) = setup_next_iter_data(\n",
    "            relabel_idx, relabel_idx_unlabeled, X_labeled, X_unlabeled, \n",
    "            true_labels_labeled, true_labels_unlabeled, pred_probs, \n",
    "            pred_probs_unlabeled, y_unlabeled\n",
    "        )\n",
    "\n",
    "    np.save(f\"results/crowdlab_{i}.npy\", crowdlab_model_accuracy_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl-dev-jupyter",
   "language": "python",
   "name": "cl-dev-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 21 2022, 22:22:30) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
